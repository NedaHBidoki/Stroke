{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx \n",
    "import os\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "import sys\n",
    "from math import log10\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "dir_ ='data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPX_data =  pd.read_excel(open(os.path.join(dir_,'20191510_Buckwalter_NPX.xlsx'),'rb'), sheet_name='NPX_Data', usecols = 'A:AUA',skiprows=5)\n",
    "NPX_panel_type = pd.read_excel(open(os.path.join(dir_,'20191510_Buckwalter_NPX.xlsx'),'rb'), sheet_name='NPX_Data', usecols = 'A:AUA',nrows=4).transpose()\n",
    "NPX_data['sel'] =NPX_data['OlinkID'].apply(lambda x:1 if str(x)[len(str(x))-2:]=='-0' else 0)\n",
    "NPX_data = NPX_data[NPX_data['sel']==1]\n",
    "NPX_data = NPX_data.drop('sel', axis=1)\n",
    "NPX_data['OlinkID']= NPX_data['OlinkID'].apply(lambda x:x[:-2] if str(x)[len(str(x))-2:]=='-0' else x)\n",
    "NPX_data = NPX_data.rename(columns={'OlinkID':'pid'})\n",
    "NPX_data['pid'] = NPX_data['pid'].apply(lambda x:int(x))\n",
    "ocols = [col for col in NPX_data.columns if 'OID' in col]\n",
    "ocols.append('pid')\n",
    "NPX_data = NPX_data[ocols]\n",
    "NPX_data = NPX_data.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = pd.read_excel(open(os.path.join(dir_,'StrokeCog_20200128_Restructured.xlsx'),'rb'), sheet_name='StrokeCog_RedCap_20200128_Olink', usecols = 'A:ML', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data['study_id'] = patient_data['study_id'].apply(lambda x: x[5:])\n",
    "patient_data = patient_data.rename(columns={'study_id': 'pid'})\n",
    "patient_data = patient_data.rename(columns={'Stroke_size':'size','demo_gender':'gender', 'nihss_total':'nihss', 'online_hhist_diabtype':'diabtype', 'online_hhist_hf':'CHF', 'online_hhist_valverepl':'hvalve', \\\n",
    "'online_hhist_pd':'Parkinsons', 'online_hhist_seiz':'seizure', 'online_hhist_dementia':'dementia','strokeToBattery_days.event_0_baseline':'timesince', \\\n",
    "'battery_age.event_0_baseline':'age', 'sis1_transformed_score.event_0_baseline':'sis1', 'sis2_transformed_score.event_0_baseline':'sis2', \\\n",
    "'sis3_transformed_score.event_0_baseline':'sis3', 'sis4_transformed_score.event_0_baseline':'sis4',\\\n",
    "'sis5_transformed_score.event_0_baseline':'sis5', 'sis6_transformed_score.event_0_baseline':'sis6', \\\n",
    "'sis7_transformed_score.event_0_baseline':'sis7', 'sis8_transformed_score.event_0_baseline':'sis8', 'facit_f_total.event_0_baseline':'facit'})\n",
    "#patient_data['sis3'].head()\n",
    "patient_data['pid'] = patient_data['pid'].apply(lambda x:int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(NPX_data['pid'].values.tolist())\n",
    "set2 = set(patient_data['pid'].values.tolist())\n",
    "intersection = set1.intersection(set2)\n",
    "NPX_data= NPX_data[NPX_data['pid'].isin(intersection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = patient_data[patient_data['pid'].isin(intersection)]\n",
    "featurenames = [\"pid\",\"size\",\"gender\",\"nihss\",\"diabtype\",\"CHF\",\"hvalve\",\n",
    "      \"Parkinsons\",\"seizure\",\"dementia\",\"timesince\",\"age\",\"sis1\",\"sis2\",\"sis3\",\"sis4\",\n",
    "      \"sis5\",\"sis6\",\"sis7\",\"sis8\",\"facit\"]\n",
    "patient_data = patient_data[featurenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from csv import writer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr +timesince+ age\n",
      "1011\n"
     ]
    }
   ],
   "source": [
    "target = ['sis3'] #['facit']\n",
    "add_fea = ['timesince','age']#,'size','gender','nihss',]#,\n",
    "str_add_fea = 'pr +' + '+ '.join(add_fea)\n",
    "print(str_add_fea)\n",
    "y_data_features = []\n",
    "y_data_features.extend(add_fea)\n",
    "y_data_features.extend(target)\n",
    "y_data_features.extend(['pid'])\n",
    "y_data = patient_data.dropna(subset=target)\n",
    "y_data = y_data[y_data_features] #'size','timesince','age',\n",
    "y_data = y_data.dropna(subset=add_fea)\n",
    "\n",
    "X = NPX_data\n",
    "\n",
    "data = y_data.merge(X,how='inner', on='pid')\n",
    "\n",
    "selected_features = [col for col in NPX_data if 'OID' in col]\n",
    "print(len(selected_features))\n",
    "selected_features.extend(add_fea)\n",
    "pids = set(data['pid'].values.tolist())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n",
      "no filter\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(fit_intercept=True)\n",
    "tru_vals = []\n",
    "predictions = []\n",
    "fs_method = 'no filter' #Available feature selection methods: 'Kristy', 'MIR', 'RF', 'l2' \n",
    "x_shape = len(selected_features)\n",
    "for i,p in enumerate(list(pids)):\n",
    "    fs_x_tr =  data[data['pid']!=p][selected_features]\n",
    "    fs_y_tr = data[data['pid']!=p][target]\n",
    "    if fs_method == 'no filter':\n",
    "        new_selected_features = selected_features\n",
    "        print('no filter')\n",
    "    else:\n",
    "        new_selected_features = fs_func(fs_method, fs_x_tr, fs_y_tr, p)\n",
    "    #print('new_selected_features:', new_selected_features)\n",
    "    x_tr = data[data['pid']!=p][new_selected_features].values.reshape(-1, len(new_selected_features))\n",
    "    y_tr = data[data['pid']!=p][target].values.reshape(-1, 1)\n",
    "    x_te = data[data['pid']==p][new_selected_features].values.reshape(-1, len(new_selected_features))\n",
    "    y_te = data[data['pid']==p][target].values.reshape(-1, 1)\n",
    "    #print(y_te.flatten())\n",
    "    tru_vals.extend(y_te.flatten())\n",
    "    model.fit(x_tr, y_tr)\n",
    "    y_pred = model.predict(x_te)\n",
    "    predictions.extend(y_pred)\n",
    "    #print('a')\n",
    "List = [type(model).__name__, fs_method+str_add_fea, target,  spearmanr(predictions, tru_vals)[0], spearmanr(predictions, tru_vals)[1],  -log10(spearmanr(predictions, tru_vals)[1])]\n",
    "file_name = 'FS/kristy_FS_%s_pvals_ipython2.csv'%target[0]\n",
    "#file_name = 'FS/test.csv'\n",
    "with open('Pvals/%s'%file_name, 'a') as f_object: \n",
    "    writer_object = writer(f_object) \n",
    "    writer_object.writerow(List) \n",
    "    f_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_func(fs_method, fs_x_tr, fs_y_tr, cv_n):\n",
    "    X = fs_x_tr.values\n",
    "    y = fs_y_tr.values\n",
    "    if fs_method == 'Kristy':\n",
    "        feat1 = get_kristy_prs()\n",
    "        feat2 = add_fea\n",
    "        k_feas = []\n",
    "        k_feas.extend(feat1)\n",
    "        k_feas.extend(feat2)\n",
    "        return k_feas\n",
    "    if fs_method == 'RF':\n",
    "        model = LogisticRegression()\n",
    "        rfe = RFE(model, 100)\n",
    "        fit = rfe.fit(X, y)\n",
    "        lst = zip(fit.ranking_, fs_x_tr.columns)\n",
    "        lst = sorted(lst, key = lambda x:np.abs(x[0]))\n",
    "    elif fs_method == 'l2':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(fs_x_tr)\n",
    "        sel_ = SelectFromModel(LogisticRegression(penalty='l2'))\n",
    "        sel_.fit(scaler.transform(fs_x_tr), fs_y_tr)\n",
    "        ridge_selected_feat = fs_x_tr.columns[(sel_.get_support())]\n",
    "        lst = zip(sel_.estimator_.coef_[0,:], fs_x_tr.columns)\n",
    "        print(sel_.estimator_.coef_)\n",
    "        lst = sorted(lst,  key = lambda x:np.abs(x[0]))\n",
    "        ridge_df = pd.DataFrame(lst, columns =['feature','Score'])\n",
    "        ridge_df ['cv']=cv_n\n",
    "        write_to_file(fs_method, ridge_df)\n",
    "        return ridge_selected_feat\n",
    "    elif fs_method == 'MIR':\n",
    "        test = SelectKBest(score_func=mutual_info_regression, k=100)\n",
    "        fit = test.fit(X, y)\n",
    "        lst = zip(fit.scores_, fs_x_tr.columns)\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    else:\n",
    "        return fs_x_tr.columns\n",
    "    fea_df = pd.DataFrame(lst, columns =['feature','Score'])\n",
    "    fea_df ['cv']=cv_n\n",
    "    write_to_file(fs_method, fea_df)\n",
    "    feas = [name for coef, name in lst[:100]]\n",
    "    #print(lst)\n",
    "    return feas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(fs_method, df):\n",
    "    #df.to_csv('FS/w-boostarpping/%s.csv'%(fs_method+str_add_fea), mode='a', header=False)\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
